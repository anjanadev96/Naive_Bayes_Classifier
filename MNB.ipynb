{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COM S 573 - Lab Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitted by Anjana Deva Prasad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('train_data.csv', names=['DocId','WordId', 'Count']) #read train_data\n",
    "train_label=pd.read_csv('train_label.csv', names=['Category'])              \n",
    "train_data.index=train_data.index+1\n",
    "train_label.index=train_label.index+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('test_data.csv', names=['DocId','WordId', 'Count']) \n",
    "test_label=pd.read_csv('test_label.csv', names=['Category'])\n",
    "test_data.index=test_data.index+1\n",
    "test_label.index=test_label.index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Vocabulary and Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61188\n"
     ]
    }
   ],
   "source": [
    "maps=pd.read_csv('map.csv', names=['Category','Category Name'])\n",
    "maps.index=maps.index+1\n",
    "vocabulary= pd.read_csv('vocabulary.txt', sep=\" \", names=['Words'])\n",
    "vocabulary.insert(0, 'WordId', range(1, 1 + len(vocabulary)))\n",
    "vocabulary.index=vocabulary.index+1\n",
    "V=len(vocabulary)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DocId  WordId  Count\n",
      "1            1       1      4\n",
      "2            1       2      2\n",
      "3            1       3     10\n",
      "4            1       4      4\n",
      "5            1       5      2\n",
      "...        ...     ...    ...\n",
      "1467341  11269   47387      1\n",
      "1467342  11269   48339      1\n",
      "1467343  11269   48919      1\n",
      "1467344  11269   51544      1\n",
      "1467345  11269   53958      1\n",
      "\n",
      "[1467345 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DocId  WordId  Count\n",
      "1           1       3      1\n",
      "2           1      10      1\n",
      "3           1      12      8\n",
      "4           1      17      1\n",
      "5           1      23      8\n",
      "...       ...     ...    ...\n",
      "967870   7505   44515      1\n",
      "967871   7505   47720      1\n",
      "967872   7505   50324      1\n",
      "967873   7505   59935      1\n",
      "967874   7505   61188      2\n",
      "\n",
      "[967874 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Category\n",
      "1             1\n",
      "2             1\n",
      "3             1\n",
      "4             1\n",
      "5             1\n",
      "...         ...\n",
      "11265        20\n",
      "11266        20\n",
      "11267        20\n",
      "11268        20\n",
      "11269        20\n",
      "\n",
      "[11269 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Category\n",
      "1            1\n",
      "2            1\n",
      "3            1\n",
      "4            1\n",
      "5            1\n",
      "...        ...\n",
      "7501        20\n",
      "7502        20\n",
      "7503        20\n",
      "7504        20\n",
      "7505        20\n",
      "\n",
      "[7505 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Prior Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_P_Omega_j(train_label):\n",
    "    p_wj=dict()\n",
    "    for i in range(1,21):\n",
    "        p_wj[i]=0\n",
    "    train_label=np.array(train_label)\n",
    "    print(train_label.shape)\n",
    "    for i in range(train_label.shape[0]):\n",
    "        val=int(train_label[i])\n",
    "        p_wj[val]+=1\n",
    "\n",
    "    for i in range(1,21):\n",
    "        p_wj[i]/=train_label.shape[0]\n",
    "\n",
    "    return dict(p_wj)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 a. Prior Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11269, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.04259472890229834,\n",
       " 2: 0.05155736977549028,\n",
       " 3: 0.05075871860857219,\n",
       " 4: 0.05208980388676901,\n",
       " 5: 0.051024935664211554,\n",
       " 6: 0.052533498979501284,\n",
       " 7: 0.051646108794036735,\n",
       " 8: 0.052533498979501284,\n",
       " 9: 0.052888455053687104,\n",
       " 10: 0.0527109770165942,\n",
       " 11: 0.05306593309078002,\n",
       " 12: 0.0527109770165942,\n",
       " 13: 0.05244475996095483,\n",
       " 14: 0.0527109770165942,\n",
       " 15: 0.052622237998047744,\n",
       " 16: 0.05315467210932647,\n",
       " 17: 0.04836276510781791,\n",
       " 18: 0.05004880646020055,\n",
       " 19: 0.04117490460555506,\n",
       " 20: 0.033365870973467035}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_wj=calculate_P_Omega_j(train_label)\n",
    "P_wj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DocId  Category\n",
      "1          1         1\n",
      "2          2         1\n",
      "3          3         1\n",
      "4          4         1\n",
      "5          5         1\n",
      "...      ...       ...\n",
      "11265  11265        20\n",
      "11266  11266        20\n",
      "11267  11267        20\n",
      "11268  11268        20\n",
      "11269  11269        20\n",
      "\n",
      "[11269 rows x 2 columns]\n",
      "      DocId  Category\n",
      "1         1         1\n",
      "2         2         1\n",
      "3         3         1\n",
      "4         4         1\n",
      "5         5         1\n",
      "...     ...       ...\n",
      "7501   7501        20\n",
      "7502   7502        20\n",
      "7503   7503        20\n",
      "7504   7504        20\n",
      "7505   7505        20\n",
      "\n",
      "[7505 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_label.insert(0, 'DocId', range(1, 1 + len(train_label))) #Insert DocId to train labels\n",
    "test_label.insert(0, 'DocId', range(1, 1 + len(test_label)))   #Insert DocId to test labels\n",
    "\n",
    "print(train_label)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocId</th>\n",
       "      <th>Category</th>\n",
       "      <th>WordId</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467341</th>\n",
       "      <td>11269</td>\n",
       "      <td>20</td>\n",
       "      <td>47387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467342</th>\n",
       "      <td>11269</td>\n",
       "      <td>20</td>\n",
       "      <td>48339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467343</th>\n",
       "      <td>11269</td>\n",
       "      <td>20</td>\n",
       "      <td>48919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467344</th>\n",
       "      <td>11269</td>\n",
       "      <td>20</td>\n",
       "      <td>51544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467345</th>\n",
       "      <td>11269</td>\n",
       "      <td>20</td>\n",
       "      <td>53958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1467345 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DocId  Category  WordId  Count\n",
       "1            1         1       1      4\n",
       "2            1         1       2      2\n",
       "3            1         1       3     10\n",
       "4            1         1       4      4\n",
       "5            1         1       5      2\n",
       "...        ...       ...     ...    ...\n",
       "1467341  11269        20   47387      1\n",
       "1467342  11269        20   48339      1\n",
       "1467343  11269        20   48919      1\n",
       "1467344  11269        20   51544      1\n",
       "1467345  11269        20   53958      1\n",
       "\n",
       "[1467345 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.merge(train_label, train_data, on='DocId')   #Merge train_data and train_label\n",
    "result.index=result.index+1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>alt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61184</th>\n",
       "      <td>61184</td>\n",
       "      <td>aeroplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61185</th>\n",
       "      <td>61185</td>\n",
       "      <td>gosple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61186</th>\n",
       "      <td>61186</td>\n",
       "      <td>ephas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61187</th>\n",
       "      <td>61187</td>\n",
       "      <td>kltensme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61188</th>\n",
       "      <td>61188</td>\n",
       "      <td>etrbom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61188 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       WordId      Words\n",
       "1           1    archive\n",
       "2           2       name\n",
       "3           3    atheism\n",
       "4           4  resources\n",
       "5           5        alt\n",
       "...       ...        ...\n",
       "61184   61184  aeroplane\n",
       "61185   61185     gosple\n",
       "61186   61186      ephas\n",
       "61187   61187   kltensme\n",
       "61188   61188     etrbom\n",
       "\n",
       "[61188 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordId</th>\n",
       "      <th>Words</th>\n",
       "      <th>DocId</th>\n",
       "      <th>Category</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>archive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>archive</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>archive</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>archive</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>archive</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474553</th>\n",
       "      <td>61184</td>\n",
       "      <td>aeroplane</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474554</th>\n",
       "      <td>61185</td>\n",
       "      <td>gosple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474555</th>\n",
       "      <td>61186</td>\n",
       "      <td>ephas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474556</th>\n",
       "      <td>61187</td>\n",
       "      <td>kltensme</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474557</th>\n",
       "      <td>61188</td>\n",
       "      <td>etrbom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1474558 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         WordId      Words  DocId  Category  Count\n",
       "0             1    archive    1.0       1.0    4.0\n",
       "1             1    archive   47.0       1.0    2.0\n",
       "2             1    archive  196.0       1.0    3.0\n",
       "3             1    archive  432.0       1.0    2.0\n",
       "4             1    archive  433.0       1.0    2.0\n",
       "...         ...        ...    ...       ...    ...\n",
       "1474553   61184  aeroplane    0.0       0.0    0.0\n",
       "1474554   61185     gosple    0.0       0.0    0.0\n",
       "1474555   61186      ephas    0.0       0.0    0.0\n",
       "1474556   61187   kltensme    0.0       0.0    0.0\n",
       "1474557   61188     etrbom    0.0       0.0    0.0\n",
       "\n",
       "[1474558 rows x 5 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1=result\n",
    "\n",
    "result1 = pd.merge(vocabulary, result, on='WordId', how='outer')\n",
    "result1=result1.fillna(0)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ij = result1.groupby(['WordId','Category']) \n",
    "p_j = result1.groupby(['Category'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 b,c Calculate n and n<sub>k</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_k=p_ij['Count'].sum()\n",
    "n=p_j['Count'].sum()\n",
    "\n",
    "\n",
    "n_k=n_k.unstack()\n",
    "n_k=n_k.fillna(0)  #Fill all the NaN terms with 0\n",
    "\n",
    "n_k=n_k.drop(n_k.columns[0], axis=1)\n",
    "n=n.drop(n.index[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "1.0     148812.0\n",
       "2.0     110358.0\n",
       "3.0      90767.0\n",
       "4.0      99146.0\n",
       "5.0      86190.0\n",
       "6.0     152846.0\n",
       "7.0      61094.0\n",
       "8.0     114102.0\n",
       "9.0     102631.0\n",
       "10.0    107898.0\n",
       "11.0    141267.0\n",
       "12.0    200456.0\n",
       "13.0    103173.0\n",
       "14.0    155338.0\n",
       "15.0    153714.0\n",
       "16.0    201267.0\n",
       "17.0    175914.0\n",
       "18.0    254805.0\n",
       "19.0    186426.0\n",
       "20.0    119096.0\n",
       "Name: Count, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n<sub>k</sub> values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>11.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>13.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>17.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>19.0</th>\n",
       "      <th>20.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WordId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61184</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61187</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61188</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61188 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Category   1.0   2.0   3.0   4.0   5.0    6.0   7.0   8.0   9.0   10.0  11.0  \\\n",
       "WordId                                                                         \n",
       "1          13.0  60.0  11.0   8.0   6.0   47.0   0.0   9.0  14.0   1.0   1.0   \n",
       "2          63.0  59.0  69.0  31.0  33.0  222.0  28.0  54.0  67.0  33.0  67.0   \n",
       "3         275.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4           9.0  17.0  17.0   0.0   1.0   79.0   2.0   0.0   4.0   2.0   0.0   \n",
       "5          82.0  14.0  21.0  10.0   1.0   15.0   2.0  13.0   4.0   1.0   1.0   \n",
       "...         ...   ...   ...   ...   ...    ...   ...   ...   ...   ...   ...   \n",
       "61184       0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "61185       0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "61186       0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "61187       0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "61188       0.0   0.0   0.0   0.0   0.0    0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "Category  12.0  13.0  14.0  15.0   16.0  17.0   18.0  19.0  20.0  \n",
       "WordId                                                            \n",
       "1         52.0   3.0  15.0  48.0    0.0  19.0   10.0   0.0   0.0  \n",
       "2         90.0  33.0  39.0  82.0  123.0  33.0  154.0  39.0  45.0  \n",
       "3          0.0   0.0   0.0   0.0   16.0   0.0    0.0   0.0   9.0  \n",
       "4         11.0   2.0  13.0  22.0    7.0   6.0    9.0  23.0   2.0  \n",
       "5         59.0   5.0  20.0  12.0   14.0  11.0    2.0  17.0  23.0  \n",
       "...        ...   ...   ...   ...    ...   ...    ...   ...   ...  \n",
       "61184      0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0  \n",
       "61185      0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0  \n",
       "61186      0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0  \n",
       "61187      0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0  \n",
       "61188      0.0   0.0   0.0   0.0    0.0   0.0    0.0   0.0   0.0  \n",
       "\n",
       "[61188 rows x 20 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Probabilities P<sub>BE</sub>  and P<sub>MLE</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_le=n_k.divide(n)\n",
    "P_be=  (n_k+1) / (n+V)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations made on P<sub>BE</sub> and P<sub>MLE</sub>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P<sub>BE</sub> values never become zero but P<sub>MLE</sub> values have lots of zeros.\n",
    "This is because for BE there is an n<sub>k</sub> +1 term that takes care of never encountering any zero probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P<sub>be</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>11.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>13.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>17.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>19.0</th>\n",
       "      <th>20.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WordId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61184</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61185</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61186</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61187</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61188</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61188 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Category      1.0       2.0       3.0       4.0       5.0       6.0   \\\n",
       "WordId                                                                 \n",
       "1         0.000067  0.000356  0.000079  0.000056  0.000047  0.000224   \n",
       "2         0.000305  0.000350  0.000461  0.000200  0.000231  0.001042   \n",
       "3         0.001314  0.000006  0.000007  0.000006  0.000007  0.000005   \n",
       "4         0.000048  0.000105  0.000118  0.000006  0.000014  0.000374   \n",
       "5         0.000395  0.000087  0.000145  0.000069  0.000014  0.000075   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "61184     0.000005  0.000006  0.000007  0.000006  0.000007  0.000005   \n",
       "61185     0.000005  0.000006  0.000007  0.000006  0.000007  0.000005   \n",
       "61186     0.000005  0.000006  0.000007  0.000006  0.000007  0.000005   \n",
       "61187     0.000005  0.000006  0.000007  0.000006  0.000007  0.000005   \n",
       "61188     0.000005  0.000006  0.000007  0.000006  0.000007  0.000005   \n",
       "\n",
       "Category      7.0       8.0       9.0       10.0      11.0      12.0  \\\n",
       "WordId                                                                 \n",
       "1         0.000008  0.000057  0.000092  0.000012  0.000010  0.000203   \n",
       "2         0.000237  0.000314  0.000415  0.000201  0.000336  0.000348   \n",
       "3         0.000008  0.000006  0.000006  0.000006  0.000005  0.000004   \n",
       "4         0.000025  0.000006  0.000031  0.000018  0.000005  0.000046   \n",
       "5         0.000025  0.000080  0.000031  0.000012  0.000010  0.000229   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "61184     0.000008  0.000006  0.000006  0.000006  0.000005  0.000004   \n",
       "61185     0.000008  0.000006  0.000006  0.000006  0.000005  0.000004   \n",
       "61186     0.000008  0.000006  0.000006  0.000006  0.000005  0.000004   \n",
       "61187     0.000008  0.000006  0.000006  0.000006  0.000005  0.000004   \n",
       "61188     0.000008  0.000006  0.000006  0.000006  0.000005  0.000004   \n",
       "\n",
       "Category      13.0      14.0      15.0      16.0      17.0      18.0  \\\n",
       "WordId                                                                 \n",
       "1         0.000024  0.000074  0.000228  0.000004  0.000084  0.000035   \n",
       "2         0.000207  0.000185  0.000386  0.000472  0.000143  0.000491   \n",
       "3         0.000006  0.000005  0.000005  0.000065  0.000004  0.000003   \n",
       "4         0.000018  0.000065  0.000107  0.000030  0.000030  0.000032   \n",
       "5         0.000037  0.000097  0.000060  0.000057  0.000051  0.000009   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "61184     0.000006  0.000005  0.000005  0.000004  0.000004  0.000003   \n",
       "61185     0.000006  0.000005  0.000005  0.000004  0.000004  0.000003   \n",
       "61186     0.000006  0.000005  0.000005  0.000004  0.000004  0.000003   \n",
       "61187     0.000006  0.000005  0.000005  0.000004  0.000004  0.000003   \n",
       "61188     0.000006  0.000005  0.000005  0.000004  0.000004  0.000003   \n",
       "\n",
       "Category      19.0      20.0  \n",
       "WordId                        \n",
       "1         0.000004  0.000006  \n",
       "2         0.000162  0.000255  \n",
       "3         0.000004  0.000055  \n",
       "4         0.000097  0.000017  \n",
       "5         0.000073  0.000133  \n",
       "...            ...       ...  \n",
       "61184     0.000004  0.000006  \n",
       "61185     0.000004  0.000006  \n",
       "61186     0.000004  0.000006  \n",
       "61187     0.000004  0.000006  \n",
       "61188     0.000004  0.000006  \n",
       "\n",
       "[61188 rows x 20 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P<sub>mle</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>11.0</th>\n",
       "      <th>12.0</th>\n",
       "      <th>13.0</th>\n",
       "      <th>14.0</th>\n",
       "      <th>15.0</th>\n",
       "      <th>16.0</th>\n",
       "      <th>17.0</th>\n",
       "      <th>18.0</th>\n",
       "      <th>19.0</th>\n",
       "      <th>20.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WordId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61184</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61185</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61186</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61187</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61188</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61188 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Category      1.0       2.0       3.0       4.0       5.0       6.0   \\\n",
       "WordId                                                                 \n",
       "1         0.000087  0.000544  0.000121  0.000081  0.000070  0.000307   \n",
       "2         0.000423  0.000535  0.000760  0.000313  0.000383  0.001452   \n",
       "3         0.001848  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4         0.000060  0.000154  0.000187  0.000000  0.000012  0.000517   \n",
       "5         0.000551  0.000127  0.000231  0.000101  0.000012  0.000098   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "61184     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61185     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61186     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61187     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61188     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "Category      7.0       8.0       9.0       10.0      11.0      12.0  \\\n",
       "WordId                                                                 \n",
       "1         0.000000  0.000079  0.000136  0.000009  0.000007  0.000259   \n",
       "2         0.000458  0.000473  0.000653  0.000306  0.000474  0.000449   \n",
       "3         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4         0.000033  0.000000  0.000039  0.000019  0.000000  0.000055   \n",
       "5         0.000033  0.000114  0.000039  0.000009  0.000007  0.000294   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "61184     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61185     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61186     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61187     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61188     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "Category      13.0      14.0      15.0      16.0      17.0      18.0  \\\n",
       "WordId                                                                 \n",
       "1         0.000029  0.000097  0.000312  0.000000  0.000108  0.000039   \n",
       "2         0.000320  0.000251  0.000533  0.000611  0.000188  0.000604   \n",
       "3         0.000000  0.000000  0.000000  0.000079  0.000000  0.000000   \n",
       "4         0.000019  0.000084  0.000143  0.000035  0.000034  0.000035   \n",
       "5         0.000048  0.000129  0.000078  0.000070  0.000063  0.000008   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "61184     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61185     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61186     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61187     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "61188     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "Category      19.0      20.0  \n",
       "WordId                        \n",
       "1         0.000000  0.000000  \n",
       "2         0.000209  0.000378  \n",
       "3         0.000000  0.000076  \n",
       "4         0.000123  0.000017  \n",
       "5         0.000091  0.000193  \n",
       "...            ...       ...  \n",
       "61184     0.000000  0.000000  \n",
       "61185     0.000000  0.000000  \n",
       "61186     0.000000  0.000000  \n",
       "61187     0.000000  0.000000  \n",
       "61188     0.000000  0.000000  \n",
       "\n",
       "[61188 rows x 20 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_le=P_le.to_dict()  #Converting Probabilities to dictionaries to make them faster\n",
    "\n",
    "P_be=P_be.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2.2 Evaluate the Performance of your Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BE(data,P_be,P_wj,V):\n",
    "    print(data)\n",
    "    df_dict=data.to_dict()\n",
    "    new_dict=defaultdict(dict)\n",
    "    \n",
    "    \n",
    "    for index in range(1,len(df_dict['DocId'])+1):\n",
    "        docId=df_dict['DocId'][index]\n",
    "        wordId=df_dict['WordId'][index]\n",
    "        count=df_dict['Count'][index]\n",
    "        new_dict[docId][wordId]=count\n",
    "        \n",
    "    new_dict=dict(new_dict)\n",
    "    \n",
    "\n",
    "    predictions=[]       \n",
    "    for docId in range(1,len(new_dict)+1):\n",
    "        score=[]\n",
    "        for category in range(1,21):\n",
    "            val=0\n",
    "            for wordId in new_dict[docId]:\n",
    "                \n",
    "                Prob=P_be[category][wordId]\n",
    "                try:\n",
    "                    power=new_dict[docId][wordId]\n",
    "                except:\n",
    "                    power=0\n",
    "                log_prob=(np.log(Prob))\n",
    "                val=val+log_prob*power\n",
    "                    \n",
    "                \n",
    "                        \n",
    "            category_prob= np.log(P_wj[category])\n",
    "            score.append(category_prob+val)\n",
    "        \n",
    "        prediction = np.argmax(score, axis=0)+1\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MLE(data,P_be,P_wj,V):\n",
    "    print(data)\n",
    "    df_dict=data.to_dict()\n",
    "    new_dict=defaultdict(dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for index in range(1,len(df_dict['DocId'])+1):\n",
    "        docId=df_dict['DocId'][index]\n",
    "        wordId=df_dict['WordId'][index]\n",
    "        count=df_dict['Count'][index]\n",
    "        new_dict[docId][wordId]=count\n",
    "        \n",
    "    new_dict=dict(new_dict)\n",
    "    \n",
    "\n",
    "    predictions=[]       \n",
    "    for docId in range(1,len(new_dict)+1):\n",
    "        score=[]\n",
    "        for category in range(1,21):\n",
    "            val=0\n",
    "            for wordId in new_dict[docId]:\n",
    "                \n",
    "                \n",
    "                Prob=P_be[category][wordId]\n",
    "                if(Prob==0):\n",
    "                    val=-math.inf             #If the Probability is zero, then a log cannot be taken. So ignore.\n",
    "                    continue\n",
    "                \n",
    "                power=new_dict[docId][wordId]\n",
    "                    #except:\n",
    "                        #power=0\n",
    "                log_prob=(np.log(Prob))\n",
    "                val=val+log_prob*power            \n",
    "            category_prob= np.log(P_wj[category])\n",
    "            score.append(category_prob+val)\n",
    "        \n",
    "        prediction = np.argmax(score, axis=0)+1\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def CalcAccuracy(predict_list,file):\n",
    "\n",
    "    df = pd.read_csv(file, names = ['Category'])\n",
    "    df.index = df.index+1\n",
    "    df['Predicted'] = pd.Series(predict_list, index = df.index)\n",
    "    match = df[df['Category'] == df['Predicted']]\n",
    "    correct = match.shape[0]\n",
    "    return (correct/df.shape[0])\n",
    "\n",
    "def CalcGroupAccuracy(predict_list,file,i):\n",
    "#     Read training Label\n",
    "    df = pd.read_csv(file, names = ['Category'])\n",
    "    df.index = df.index+1\n",
    "    df['Predicted'] = pd.Series(predict_list, index = df.index)\n",
    "    df=df[df['Category']==i]\n",
    "    match = df[df['Category'] == df['Predicted']]\n",
    "    correct = match.shape[0]\n",
    "    return (correct/df.shape[0])\n",
    "\n",
    "def ConfusionMatrix(predict_list,file):\n",
    "#     Read training Label\n",
    "    confusion_matrix=[[0]*21]*21\n",
    "    count=0\n",
    "    df = pd.read_csv(file, names = ['Category'])\n",
    "    df.index = df.index+1\n",
    "    df['Predicted'] = pd.Series(predict_list, index = df.index)\n",
    "    for i in range(1,21):\n",
    "        row=df[ df['Category']==i]\n",
    "        for j in range(1,21):\n",
    "            match = row[row['Predicted']==j]\n",
    "            count=match.shape[0]\n",
    "            confusion_matrix[i][j]=count\n",
    "        print(confusion_matrix[i][1:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2.2.1 Performance on Training Data           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on train data for BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DocId  WordId  Count\n",
      "1            1       1      4\n",
      "2            1       2      2\n",
      "3            1       3     10\n",
      "4            1       4      4\n",
      "5            1       5      2\n",
      "...        ...     ...    ...\n",
      "1467341  11269   47387      1\n",
      "1467342  11269   48339      1\n",
      "1467343  11269   48919      1\n",
      "1467344  11269   51544      1\n",
      "1467345  11269   53958      1\n",
      "\n",
      "[1467345 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions_train_be=BE(train_data,P_be,P_wj,V)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on train data for MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DocId  WordId  Count\n",
      "1            1       1      4\n",
      "2            1       2      2\n",
      "3            1       3     10\n",
      "4            1       4      4\n",
      "5            1       5      2\n",
      "...        ...     ...    ...\n",
      "1467341  11269   47387      1\n",
      "1467342  11269   48339      1\n",
      "1467343  11269   48919      1\n",
      "1467344  11269   51544      1\n",
      "1467345  11269   53958      1\n",
      "\n",
      "[1467345 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions_train_mle=MLE(train_data,P_le,P_wj,V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for BE on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.10772916851539\n"
     ]
    }
   ],
   "source": [
    "accuracy_train_BE = CalcAccuracy(predictions_train_be,'train_label.csv')\n",
    "print(accuracy_train_BE*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for MLE on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.1214837163901\n"
     ]
    }
   ],
   "source": [
    "accuracy_train_MLE = CalcAccuracy(predictions_train_mle,'train_label.csv')\n",
    "print(accuracy_train_MLE*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class accuracy for BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  0.9666666666666667\n",
      "2  :  0.919104991394148\n",
      "3  :  0.8793706293706294\n",
      "4  :  0.9301533219761499\n",
      "5  :  0.9408695652173913\n",
      "6  :  0.9493243243243243\n",
      "7  :  0.7749140893470791\n",
      "8  :  0.9662162162162162\n",
      "9  :  0.9630872483221476\n",
      "10  :  0.9713804713804713\n",
      "11  :  0.9782608695652174\n",
      "12  :  0.9797979797979798\n",
      "13  :  0.9238578680203046\n",
      "14  :  0.9764309764309764\n",
      "15  :  0.9780775716694773\n",
      "16  :  0.9833055091819699\n",
      "17  :  0.9853211009174312\n",
      "18  :  0.9680851063829787\n",
      "19  :  0.9698275862068966\n",
      "20  :  0.7606382978723404\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,21):\n",
    "    group_accuracy=CalcGroupAccuracy(predictions_train_be,'train_label.csv',i)\n",
    "    print(i,\" : \",group_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Accuracy for MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  0.9979166666666667\n",
      "2  :  0.9793459552495697\n",
      "3  :  0.9912587412587412\n",
      "4  :  0.9880749574105622\n",
      "5  :  0.9895652173913043\n",
      "6  :  0.9847972972972973\n",
      "7  :  0.993127147766323\n",
      "8  :  0.9915540540540541\n",
      "9  :  0.9966442953020134\n",
      "10  :  0.9932659932659933\n",
      "11  :  0.9899665551839465\n",
      "12  :  1.0\n",
      "13  :  0.9898477157360406\n",
      "14  :  0.9966329966329966\n",
      "15  :  0.9966273187183811\n",
      "16  :  0.988313856427379\n",
      "17  :  0.9963302752293578\n",
      "18  :  0.9911347517730497\n",
      "19  :  0.9870689655172413\n",
      "20  :  0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,21):\n",
    "    group_accuracy=CalcGroupAccuracy(predictions_train_mle,'train_label.csv',i)\n",
    "    print(i,\" : \",group_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[464, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 11, 0, 1, 1, 2]\n",
      "[1, 534, 6, 15, 1, 9, 2, 0, 1, 0, 0, 2, 1, 1, 2, 4, 0, 0, 2, 0]\n",
      "[1, 10, 503, 23, 1, 20, 2, 0, 0, 0, 0, 7, 1, 1, 0, 2, 0, 0, 1, 0]\n",
      "[0, 10, 4, 546, 4, 4, 6, 2, 0, 0, 0, 0, 3, 0, 1, 2, 0, 2, 2, 1]\n",
      "[2, 5, 2, 7, 541, 3, 1, 0, 2, 0, 0, 2, 1, 2, 2, 3, 0, 1, 1, 0]\n",
      "[0, 11, 8, 1, 2, 562, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 1, 0, 1, 0]\n",
      "[2, 3, 2, 34, 6, 2, 451, 17, 1, 3, 3, 16, 15, 5, 4, 5, 5, 1, 7, 0]\n",
      "[1, 0, 0, 3, 1, 2, 3, 572, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 3, 1]\n",
      "[0, 1, 0, 1, 1, 0, 4, 1, 574, 0, 0, 0, 0, 2, 0, 2, 6, 1, 3, 0]\n",
      "[0, 3, 0, 1, 0, 1, 1, 3, 0, 577, 4, 0, 0, 1, 0, 1, 2, 0, 0, 0]\n",
      "[1, 0, 1, 2, 0, 1, 0, 2, 0, 0, 585, 1, 0, 0, 0, 1, 0, 2, 2, 0]\n",
      "[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 582, 0, 1, 0, 0, 3, 1, 5, 0]\n",
      "[1, 4, 0, 15, 5, 0, 3, 2, 0, 0, 1, 5, 546, 2, 2, 1, 2, 0, 2, 0]\n",
      "[0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, 580, 0, 5, 2, 0, 1, 0]\n",
      "[2, 2, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 2, 580, 1, 0, 0, 2, 0]\n",
      "[0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 589, 1, 3, 2, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 537, 2, 3, 0]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 2, 0, 6, 0, 546, 5, 0]\n",
      "[2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 1, 0, 1, 2, 2, 450, 0]\n",
      "[25, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 39, 15, 4, 4, 286]\n"
     ]
    }
   ],
   "source": [
    "ConfusionMatrix(predictions_train_be,'train_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[479, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 569, 2, 4, 1, 1, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 4, 567, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 2, 1, 580, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 1, 569, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "[0, 5, 2, 0, 0, 583, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1, 578, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 1, 587, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 1, 0, 594, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 590, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 592, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 594, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 585, 1, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 592, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 591, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 592, 1, 0, 0, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 543, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 559, 1, 0]\n",
      "[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 458, 1]\n",
      "[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 1, 368]\n"
     ]
    }
   ],
   "source": [
    "ConfusionMatrix(predictions_train_mle,'train_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.2 Performance on testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on test data for BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DocId  WordId  Count\n",
      "1           1       3      1\n",
      "2           1      10      1\n",
      "3           1      12      8\n",
      "4           1      17      1\n",
      "5           1      23      8\n",
      "...       ...     ...    ...\n",
      "967870   7505   44515      1\n",
      "967871   7505   47720      1\n",
      "967872   7505   50324      1\n",
      "967873   7505   59935      1\n",
      "967874   7505   61188      2\n",
      "\n",
      "[967874 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions_test_be=BE(test_data,P_be,P_wj,V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on test data for MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DocId  WordId  Count\n",
      "1           1       3      1\n",
      "2           1      10      1\n",
      "3           1      12      8\n",
      "4           1      17      1\n",
      "5           1      23      8\n",
      "...       ...     ...    ...\n",
      "967870   7505   44515      1\n",
      "967871   7505   47720      1\n",
      "967872   7505   50324      1\n",
      "967873   7505   59935      1\n",
      "967874   7505   61188      2\n",
      "\n",
      "[967874 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions_test_mle=MLE(test_data,P_le,P_wj,V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for BE on test data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.10792804796802\n"
     ]
    }
   ],
   "source": [
    "accuracy_test_BE = CalcAccuracy(predictions_test_be,'test_label.csv')\n",
    "print(accuracy_test_BE*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for MLE on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.460359760159893\n"
     ]
    }
   ],
   "source": [
    "accuracy_test_MLE = CalcAccuracy(predictions_test_mle,'test_label.csv')\n",
    "print(accuracy_test_MLE*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Accuracy for BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  73.89937106918238\n",
      "2  :  76.09254498714652\n",
      "3  :  52.94117647058824\n",
      "4  :  77.8061224489796\n",
      "5  :  71.27937336814621\n",
      "6  :  78.46153846153847\n",
      "7  :  59.16230366492147\n",
      "8  :  90.12658227848101\n",
      "9  :  88.9168765743073\n",
      "10  :  86.90176322418137\n",
      "11  :  95.48872180451127\n",
      "12  :  91.39240506329114\n",
      "13  :  65.9033078880407\n",
      "14  :  82.44274809160305\n",
      "15  :  85.45918367346938\n",
      "16  :  94.72361809045226\n",
      "17  :  89.28571428571429\n",
      "18  :  86.43617021276596\n",
      "19  :  59.354838709677416\n",
      "20  :  35.45816733067729\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,21):\n",
    "    group_accuracy=CalcGroupAccuracy(predictions_test_be,'test_label.csv',i)\n",
    "    print(i,\" : \",group_accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Accuracy for MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  0.9937106918238994\n",
      "2  :  0.06683804627249357\n",
      "3  :  0.04859335038363171\n",
      "4  :  0.07142857142857142\n",
      "5  :  0.057441253263707574\n",
      "6  :  0.08461538461538462\n",
      "7  :  0.12041884816753927\n",
      "8  :  0.04810126582278481\n",
      "9  :  0.05037783375314862\n",
      "10  :  0.05289672544080604\n",
      "11  :  0.09022556390977443\n",
      "12  :  0.043037974683544304\n",
      "13  :  0.020356234096692113\n",
      "14  :  0.035623409669211195\n",
      "15  :  0.04336734693877551\n",
      "16  :  0.0678391959798995\n",
      "17  :  0.03296703296703297\n",
      "18  :  0.0398936170212766\n",
      "19  :  0.025806451612903226\n",
      "20  :  0.02390438247011952\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,21):\n",
    "    group_accuracy=CalcGroupAccuracy(predictions_test_mle,'test_label.csv',i)\n",
    "    print(i,\" : \",group_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 2, 3, 45, 3, 10, 7, 9]\n",
      "[3, 296, 6, 12, 7, 22, 1, 3, 2, 0, 0, 17, 4, 4, 7, 4, 0, 0, 1, 0]\n",
      "[3, 33, 207, 58, 11, 31, 0, 2, 2, 2, 1, 17, 1, 4, 4, 5, 0, 0, 9, 1]\n",
      "[0, 8, 15, 305, 21, 2, 4, 6, 0, 0, 1, 6, 23, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 8, 10, 37, 273, 3, 4, 4, 1, 1, 0, 6, 17, 8, 2, 0, 3, 0, 6, 0]\n",
      "[0, 42, 7, 10, 2, 306, 1, 0, 2, 1, 0, 10, 0, 0, 3, 2, 1, 1, 2, 0]\n",
      "[0, 8, 4, 50, 20, 1, 226, 33, 5, 0, 1, 3, 11, 2, 3, 4, 2, 3, 6, 0]\n",
      "[1, 1, 0, 2, 0, 1, 5, 356, 4, 2, 0, 1, 4, 0, 2, 1, 4, 2, 9, 0]\n",
      "[0, 1, 0, 0, 0, 0, 0, 26, 353, 2, 0, 1, 1, 1, 0, 1, 4, 2, 5, 0]\n",
      "[4, 1, 0, 1, 1, 2, 3, 3, 1, 345, 17, 2, 2, 0, 0, 3, 1, 2, 9, 0]\n",
      "[2, 0, 0, 0, 0, 0, 1, 1, 0, 4, 381, 1, 0, 2, 1, 2, 0, 1, 3, 0]\n",
      "[0, 4, 1, 1, 2, 1, 1, 0, 0, 0, 0, 361, 3, 2, 0, 2, 8, 0, 8, 1]\n",
      "[2, 18, 0, 27, 8, 3, 1, 10, 2, 0, 0, 46, 259, 6, 3, 6, 0, 2, 0, 0]\n",
      "[10, 7, 1, 3, 0, 0, 0, 4, 0, 1, 0, 1, 3, 324, 3, 17, 3, 6, 10, 0]\n",
      "[3, 7, 0, 0, 0, 2, 0, 0, 1, 0, 1, 4, 4, 4, 335, 5, 1, 2, 22, 1]\n",
      "[7, 2, 1, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 377, 2, 2, 1, 1]\n",
      "[1, 0, 0, 0, 1, 0, 1, 2, 1, 1, 1, 3, 0, 1, 2, 3, 325, 2, 16, 4]\n",
      "[12, 1, 0, 0, 0, 0, 0, 2, 1, 1, 1, 4, 0, 0, 0, 8, 3, 325, 18, 0]\n",
      "[6, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 3, 0, 3, 7, 3, 95, 5, 184, 1]\n",
      "[47, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 3, 5, 70, 19, 5, 8, 89]\n"
     ]
    }
   ],
   "source": [
    "ConfusionMatrix(predictions_test_be,'test_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "[352, 26, 2, 1, 1, 4, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0]\n",
      "[354, 3, 19, 6, 3, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 1, 0, 0, 0]\n",
      "[350, 3, 5, 28, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[351, 2, 0, 2, 22, 0, 1, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0]\n",
      "[351, 2, 0, 1, 1, 33, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "[317, 4, 2, 4, 1, 0, 46, 2, 2, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n",
      "[369, 0, 0, 0, 0, 0, 1, 19, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1]\n",
      "[376, 0, 0, 0, 0, 0, 0, 1, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[372, 0, 0, 0, 0, 0, 1, 0, 0, 21, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[363, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[375, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 17, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[373, 1, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 8, 1, 1, 0, 0, 0, 0, 0]\n",
      "[375, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 14, 0, 0, 1, 0, 0, 0]\n",
      "[375, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 0, 0, 0, 0, 0]\n",
      "[367, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 27, 0, 1, 1, 1]\n",
      "[350, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 1, 0, 1]\n",
      "[358, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 15, 0, 0]\n",
      "[297, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 0, 8, 0]\n",
      "[237, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 4, 0, 0, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "ConfusionMatrix(predictions_test_mle,'test_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations made on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bayesian Estimate works well and predicts the training data with a 94.1% accuracy.\n",
    "- Maximum Likelihood works very well on the training data with accuracy as high as 99.1%\n",
    "- For the training data, Maximum Likelihood Estimate performs better than Bayesian Estimate\n",
    "- Based on observations made on the Class accuracy values, BE does well in most classes with an accuracy of         greater than 90% but does poorly on classes 7,20 and 3 with resp accuracies below 80% for the 7,20 and around     87% for class 3.\n",
    "- Based on observations made on the Class accuracy values, MLE performs exceedingly well for Class 12 with a 100%   class accuracy and has 97% accuracy and more for all the other classes.\n",
    "- The Confusion Matrix of MLE is more populated than BE along the major diagonal. This means that MLE predicts       higher classes correctly, which explains why the accuracy of MLE is more than that of BE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations made on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BE performs reasonably well on test data as well with an accuracy of 78%.\n",
    "- MLE performs poorly on test data with an accuracy of around 9.5%\n",
    "- BE performs better than MLE on test data.\n",
    "- Based on the class accuracy values, it is found that BE performs better than 75%(approx) because of higher         accuracy among class predictions with 90% for most of them and some around 60%. Only class 20 has poor             performance with hust 35% accuracy.\n",
    "- MLE performs well with a 99% accuracy for the first Group and poorly for every other class. This means that the   only Class 1 is identified correctly by MLE and most other documents are also identified as class 1.\n",
    "- The confusion matrix of BE is densely filled on the major diagonal but it still has inconsistencies all over the   matrix. This might explain the 74% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, Bayesian Estimation has a better overall performance than Maximum Likelihood Estimation because MLE overfits for the training data and has a very poor performance on the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
